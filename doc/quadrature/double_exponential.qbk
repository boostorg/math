[/
Copyright (c) 2017 Nick Thompson
Use, modification and distribution are subject to the
Boost Software License, Version 1.0. (See accompanying file
LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
]

[section:double_exponential Double-exponential quadrature]

[heading Synopsis]

``
    #include <boost/math/quadrature/tanh_sinh.hpp>
    #include <boost/math/quadrature/exp_sinh.hpp>
    #include <boost/math/quadrature/sinh_sinh.hpp>

    namespace boost{ namespace math{

    template<class Real>
    class tanh_sinh
    {
    public:
        tanh_sinh(Real tol = sqrt(std::numeric_limits<Real>::epsilon()), size_t max_refinements = 15);

        template<class F>
        Real integrate(const F f, Real a, Real b, Real* error = nullptr, Real* L1 = nullptr) const;
    }

    template<class Real>
    class exp_sinh
    {
    public:
        exp_sinh(Real tol = sqrt(std::numeric_limits<Real>::epsilon()), size_t max_refinements = 9);

        template<class F>
        Real integrate(const F f, Real a = 0, Real b = std::numeric_limits<Real>::infinity(), Real* error = nullptr, Real* L1 = nullptr) const;
    }

    template<class Real>
    class sinh_sinh
    {
    public:
        sinh_sinh(Real tol = sqrt(std::numeric_limits<Real>::epsilon()), size_t max_refinements = 9);

        template<class F>
        Real integrate(const F f, Real* error = nullptr, Real* L1 = nullptr) const;
    }

}}
``

[heading Overview]

The tanh-sinh quadrature routine provided by boost is a rapidly convergent numerical integration scheme for holomorphic integrands.
By this we mean that the integrand is the restriction to the real line of a complex-differentiable function which is bounded on the interior of the unit disk /|z| < 1/,
so that it lies within the so-called [@https://en.wikipedia.org/wiki/Hardy_space Hardy space].
If your integrand obeys these conditions, it can be shown that tanh-sinh integration is optimal,
in the sense that it requires the fewest function evaluations for a given accuracy of any quadrature algorithm for a random element from the Hardy space.
A basic example of how to use the tanh-sinh quadrature is shown below:

    tanh_sinh<double> integrator;
    auto f = [](double x) { return 5*x + 7; };
    double Q = integrator.integrate(f, (double) 0, (double) 1);

The basic idea of tanh-sinh quadrature is that a variable transformation can cause the endpoint derivatives to decay rapidly.
When the derivatives at the endpoints decay much faster than the Bernoulli numbers grow,
the Euler-Maclaurin summation formula tells us that simple trapezoidal quadrature converges exponentially fast.


One very nice property of tanh-sinh quadrature is that it can handle singularities at the endpoints of the integration domain.
For instance, the following integrand, singular at both endpoints, can be efficiently evaluated to 100 binary digits:

    auto f = [](Real x) { return log(x)*log(1-x); };
    Real Q = integrator.integrate(f, (Real) 0, (Real) 1);

Although boost's implementation of tanh-sinh quadrature can achieve very high precision, it is not truly arbitrary precision.
The reason is that vast speed improvements can be obtained by caching the weights and abscissas of the variable transformation

    tanh(half_pi<Real>()*sinh(t));

These numbers have been precomputed up to 100 binary digits, so this is roughly the most precision that can be expected from the quadrature.
We think that this is a reasonable compromise between efficiency, accuracy, and compile time that will satisfy the vast majority of users.


Now onto the caveats: As stated before, the integrands must lie in a Hardy space to ensure rapid convergence.
Attempting to integrate a function which is not bounded on the unit disk by tanh-sinh can lead to very slow convergence.
For example, take the Runge function:

    auto f1 = [](double t) { return 1/(1+25*t*t); };
    Q = integrator.integrate(f1, (double) -1, (double) 1);

This function has poles at \u00B1 \u2148/5, and as such it is not bounded on the unit disk.
However, the related function

    auto f2 = [](double t) { return 1/(1+0.04*t*t); };
    Q = integrator.integrate(f2, (double) -1, (double) 1);

has poles outside the unit disk (at \u00B1 5\u2148), and is therefore in the Hardy space.
The integration is performed 22x faster for the second function!
If you do not understand the structure of your integrand in the complex plane, do performance testing before deployment.

Like the trapezoidal quadrature, the tanh-sinh quadrature produces an estimate of the L[sub 1] norm of the integral along with the requested integral.
This is to establish a scale against which to measure the tolerance, and provides an estimate of the condition number of the summation.
This can be queries as follows:


    tanh_sinh<double> integrator;
    auto f = [](double x) { return 5*x + 7; };
    double error;
    double L1;
    double Q = integrator.integrate(f, (double) 0, (double) 1, &error, &L1);
    double condition_number = L1/std::abs(Q);

If the condition number is large, the computed integral is worthless.

Although the tanh-sinh quadrature can compute integral over infinite domains by variable transformations, these transformations can create a very poorly behaved integrand.
For this reason, double-exponential variable transformations have been provided that allow stable computation over infinite domains; these being the exp-sinh and sinh-sinh quadrature.

The sinh-sinh quadrature allows computation over the entire real line, and is called as follows:

    sinh_sinh<double> integrator;
    auto f = [](double x) { return exp(-x*x); };
    double error;
    double L1;
    double Q = integrator.integrate(f, &error, &L1);

Note that the limits of integration are understood to be (-\u221E, \u221E).

For half-infinite intervals, the exp-sinh quadrature is provided:

    exp_sinh<double> integrator;
    auto f = [](double x) { return exp(-3*x); };
    double error;
    double L1;
    double Q = integrator.integrate(f, (Real) 0, std::numeric_limits<Real>::infinity(), &error, &L1);

Either the left limit or the right limit must be infinite; not both.
Endpoint singularities are supported by sinh-sinh and exp-sinh.
These quadrature algorithms are truly arbitrary precision, but this requires the abscissas and weights to be computed at runtime.
This means that the call to the constructor is expensive, so make sure to reuse the object for multiple integrations (if, say you are assembling a stiffness matrix).
Subsequent calls the `integrator.integrate` are threadsafe, so assembling a stiffness matrix can be done in parallel.

[heading Tolerance and Max-interval Halvings]

The constructor for all three double-exponential quadratures supports two additional arguments: A tolerance and max-interval halvings.
The tolerance is met when two subsequent estimates of the integral have absolute error less than `tol*L1`.
It is highly recommended that the tolerance be left at the default value of [radic][epsilon].
Since double exponential quadrature converges exponentially fast for functions in Hardy spaces, then once the routine has *proved* that the error is ~[radic][epsilon],
then the error in fact is ~[epsilon].
If you request that the error be ~[epsilon], this tolerance might never be achieved (as the summation is not stabilized ala Kahan), and the routine will simply flounder,
dividing the interval in half in order to increase the precision of the integrand, only to be thwarted by floating point roundoff.

The max interval halvings is the maximum number number of times the interval can be cut in half before giving up.
If the accuracy is not met at that time, the routine returns its best estimate, along with the `error` and `L1`,
which allows the user to decide if another quadrature routine should be employed.

An example of this is

    double tol = std::sqrt(std::numeric_limits<double>::epsilon());
    size_t max_halvings = 12;
    tanh_sinh<double> integrator(tol, max_halvings);
    auto f = [](double x) { return 5*x + 7; };
    double error, L1;
    double Q = integrator.integrate(f, (double) 0, (double) 1, &error, &L1);
    if (error*L1 > 0.01)
    {
        Q = some_other_quadrature_method(f, (double) 0, (double) 1);
    }

[heading Caveats]

A few things to keep in mind while using the tanh-sinh, exp-sinh, and sinh-sinh quadratures:

These routines are *very* aggressive about approaching the endpoint singularities.
This allows lots of significant digits to be extracted, but also has another problem: Roundoff error can cause the function to be evaluated at the endpoints.
A few ways to avoid this: Narrow up the bounds of integration to say, [a + [epsilon], b - [epsilon]], make sure (a+b)/2 and (b-a)/2 are representable, and finally, if you think the compromise between accuracy an usability has gone too far in the direction of accuracy, file a ticket.

Both exp-sinh and sinh-sinh quadratures evaluate the functions they are passed at *very* large argument.
You might understand that x[super 12]exp(-x) is should be zero when x[super 12] overflows, but IEEE floating point arithmetic does not.
Hence `std::pow(x, 12)*std::exp(-x)` is an indeterminate form whenever `std::pow(x, 12)` overflows.
So make sure your functions have the correct limiting behavior; for example

    auto f = [](double x) {
        double t = exp(-x);
        if(t == 0)
        {
            return 0;
        }
        return t*pow(x, 12);
    };

has the correct behavior for large /x/, but `auto f = [](double x) { return exp(-x)*pow(x, 12); };` does not.

Oscillatory integrals, such as the sinc integral, are poorly approximated by double-exponential quadrature.
Fortunately the error estimates and L1 norm are massive for these integrals, but nonetheless, oscillatory integrals require different techniques.

References:

Tanaka, Kenâ€™ichiro, et al. ['Function classes for double exponential integration formulas.] Numerische Mathematik 111.4 (2009): 631-655.

[endsect]
